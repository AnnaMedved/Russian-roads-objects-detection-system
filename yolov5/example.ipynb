{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527c9541-0502-412e-b811-b9c5f4606a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "\n",
    "# путь до сохранения артефактов\n",
    "DETECT_IMAGES = 'files_obr/'\n",
    "# path images\n",
    "SAVE_IMAGES = 'files_obr/save_images/'\n",
    "# загрузка словаря замен\n",
    "dict_synth = {\n",
    "    'fissure': 0, \n",
    "    'large_pit': 1, \n",
    "    'small_pit': 2, \n",
    "    'patch': 3\n",
    "}\n",
    "\n",
    "@torch.no_grad()\n",
    "def detect(\n",
    "    source,\n",
    "    model,\n",
    "    imgsz=(1280, 1280),  # inference size (height, width)\n",
    "    conf_thres=0.3,  # confidence threshold\n",
    "    iou_thres=0.4,  # NMS IOU threshold\n",
    "    max_det=1000,  # maximum detections per image\n",
    "    device='cpu',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "    view_img=False,  # show results\n",
    "    save_txt=True,  # save results to *.txt\n",
    "    save_conf=False,  # save confidences in --save-txt labels\n",
    "    save_crop=False,  # save cropped prediction boxes\n",
    "    nosave=False,  # do not save images/videos\n",
    "    classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "    agnostic_nms=False,  # class-agnostic NMS\n",
    "    augment=False,  # augmented inference\n",
    "    visualize=True,  # visualize features\n",
    "    update=False,  # update all models\n",
    "    line_thickness=3,  # bounding box thickness (pixels)\n",
    "    hide_labels=False,  # hide labels\n",
    "    hide_conf=True,  # hide confidences\n",
    "    half=False,  # use FP16 half-precision inference\n",
    "    dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для представления результата.\n",
    "    \"\"\"\n",
    "    source = str(source)\n",
    "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    # Directories\n",
    "    save_dir = increment_path(DETECT_IMAGES, True)\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "    # \n",
    "    save_path_origin = str(save_dir/ 'images' / source)\n",
    "    \n",
    "    # формирование изображения\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
    "    print(dataset)\n",
    "    bs = 1  # batch_size\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "\n",
    "    # Run inference\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0], 0\n",
    "    all_labels = []\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        visualize = increment_path(DETECT_IMAGES, True) \n",
    "        pred = model(im, augment=augment, visualize=False)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # NMS\n",
    "        print(pred)\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "        print(pred)\n",
    "        # Process predictions\n",
    "        for i, det in enumerate(pred):  # per image\n",
    "            seen += 1\n",
    "            p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir/ 'detection_images' / p.name)  # im.jpg\n",
    "            #save_path_origin = str(save_dir/ 'images' / p.name)\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "            # сохранение исходного изображения\n",
    "            #cv2.imwrite(save_path_origin, im0)\n",
    "            annotator = Annotator(im0, line_width=line_thickness, pil=True, example=str(names))\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if save_txt:  # Write to file\n",
    "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "                        file_check_txt = txt_path + '.txt'\n",
    "                        with open(file_check_txt, 'a') as f:\n",
    "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                    if save_img or save_crop or view_img:  # Add bbox to image\n",
    "                        c = int(cls)  # integer class\n",
    "                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                        label = label.replace('dustbin', 'rubbish').replace('graffiti', 'advertising')\n",
    "                        label_id = dict_synth[label]\n",
    "                        all_labels.append(label_id)\n",
    "                        annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "                        if save_crop:\n",
    "                            save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if view_img:\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:  # 'video' or 'stream'\n",
    "                    if vid_path != save_path:  # new video\n",
    "                        vid_path = save_path\n",
    "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                            vid_writer.release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                            save_path += '.mp4'\n",
    "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    vid_writer.write(im0)\n",
    "        # Print time (inference-only)\n",
    "        LOGGER.info(f'{s}Done. ({t3 - t2:.3f}s)')\n",
    "\n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)\n",
    "        \n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4db9a86-badf-4671-8dbf-e6844bc35821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-8-4 Python-3.8.9 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7020913 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<utils.dataloaders.LoadImages object at 0x000001EB65C87F10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (1/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 large_pit, Done. (0.739s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.07478e+00, 3.84110e+00, 1.13329e+01,  ..., 5.79258e-02, 1.56464e-01, 4.88118e-02],\n",
      "         [1.31127e+01, 4.37240e+00, 2.62743e+01,  ..., 8.29889e-02, 8.23497e-02, 2.99626e-02],\n",
      "         [2.16633e+01, 4.40853e+00, 3.68172e+01,  ..., 7.59848e-02, 7.06259e-02, 2.53337e-02],\n",
      "         ...,\n",
      "         [1.18981e+03, 7.22848e+02, 4.99502e+01,  ..., 9.61916e-01, 6.09811e-02, 5.79022e-03],\n",
      "         [1.24253e+03, 7.03872e+02, 3.06883e+01,  ..., 9.76614e-01, 4.69240e-02, 5.33756e-03],\n",
      "         [1.26644e+03, 6.97134e+02, 2.29209e+01,  ..., 9.75999e-01, 4.59910e-02, 6.97561e-03]]])\n",
      "[tensor([[220.77888, 362.79608, 236.40456, 401.43146,   0.40480,   1.00000]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (2/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 2 fissures, Done. (0.864s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.27951e+00, 4.81753e+00, 1.06754e+01,  ..., 5.48449e-02, 1.32472e-01, 5.30691e-02],\n",
      "         [1.31659e+01, 5.08908e+00, 2.77154e+01,  ..., 7.98790e-02, 5.92592e-02, 4.25294e-02],\n",
      "         [2.08050e+01, 4.44220e+00, 3.47215e+01,  ..., 7.56741e-02, 5.20326e-02, 3.89795e-02],\n",
      "         ...,\n",
      "         [1.22314e+03, 7.13274e+02, 3.02590e+01,  ..., 9.64496e-01, 5.59728e-02, 8.59657e-03],\n",
      "         [1.23072e+03, 7.11640e+02, 2.65239e+01,  ..., 9.59933e-01, 6.54999e-02, 1.29187e-02],\n",
      "         [1.27162e+03, 7.14850e+02, 2.27391e+01,  ..., 9.43693e-01, 9.52230e-02, 1.26413e-02]]])\n",
      "[tensor([[4.15096e+02, 6.74404e+02, 4.56028e+02, 7.24585e+02, 6.41982e-01, 0.00000e+00],\n",
      "        [4.40553e+02, 3.68304e+02, 5.87998e+02, 3.77482e+02, 3.10759e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (3/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 patch, Done. (0.931s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.93647e+00, 4.11082e+00, 9.80752e+00,  ..., 4.88028e-01, 9.09141e-02, 3.63892e-02],\n",
      "         [1.28122e+01, 4.93007e+00, 2.56386e+01,  ..., 6.56087e-01, 4.56942e-02, 2.03670e-02],\n",
      "         [1.80427e+01, 4.42353e+00, 3.37023e+01,  ..., 3.50515e-01, 5.79614e-02, 2.57037e-02],\n",
      "         ...,\n",
      "         [1.21286e+03, 7.21446e+02, 3.78134e+01,  ..., 9.11214e-01, 1.65622e-01, 8.70901e-03],\n",
      "         [1.23279e+03, 7.17914e+02, 3.29848e+01,  ..., 9.19835e-01, 1.56385e-01, 1.07438e-02],\n",
      "         [1.27604e+03, 7.26416e+02, 2.66674e+01,  ..., 8.17241e-01, 2.60987e-01, 1.23231e-02]]])\n",
      "[tensor([[5.76881e+02, 4.12866e+02, 6.13290e+02, 4.24402e+02, 4.21981e-01, 3.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (4/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 patch, Done. (0.790s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.83950e+00, 5.63076e+00, 1.24692e+01,  ..., 7.89455e-02, 1.28639e-01, 4.49839e-02],\n",
      "         [1.25420e+01, 6.10300e+00, 2.60121e+01,  ..., 1.03850e-01, 7.07937e-02, 2.56207e-02],\n",
      "         [1.88541e+01, 5.15785e+00, 3.27631e+01,  ..., 1.01026e-01, 1.25795e-01, 2.52325e-02],\n",
      "         ...,\n",
      "         [1.20709e+03, 7.28840e+02, 5.32986e+01,  ..., 9.21343e-01, 1.23676e-01, 8.58964e-03],\n",
      "         [1.24379e+03, 7.29717e+02, 4.21562e+01,  ..., 9.00486e-01, 1.49942e-01, 1.25077e-02],\n",
      "         [1.27000e+03, 7.30237e+02, 3.47040e+01,  ..., 7.25283e-01, 2.78040e-01, 1.52387e-02]]])\n",
      "[tensor([[5.69849e+02, 4.21682e+02, 6.08814e+02, 4.34237e+02, 4.95700e-01, 3.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (5/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 patch, Done. (0.741s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.13679e+00, 5.52119e+00, 8.42420e+00,  ..., 3.84387e-01, 1.12520e-01, 2.38759e-02],\n",
      "         [1.10366e+01, 4.88519e+00, 2.24330e+01,  ..., 4.56688e-01, 8.22112e-02, 2.17527e-02],\n",
      "         [1.93573e+01, 4.20195e+00, 3.16636e+01,  ..., 3.94529e-01, 9.88537e-02, 1.46400e-02],\n",
      "         ...,\n",
      "         [1.20993e+03, 7.13844e+02, 3.17967e+01,  ..., 9.05685e-01, 1.42699e-01, 9.72434e-03],\n",
      "         [1.23698e+03, 7.15625e+02, 3.37021e+01,  ..., 8.79872e-01, 2.22000e-01, 1.39486e-02],\n",
      "         [1.26359e+03, 7.17955e+02, 3.96262e+01,  ..., 8.54885e-01, 2.51411e-01, 2.25340e-02]]])\n",
      "[tensor([[5.61967e+02, 4.33768e+02, 6.05491e+02, 4.46572e+02, 5.84451e-01, 3.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (6/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.744s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.74127e+00, 8.07300e+00, 8.42084e+00,  ..., 2.56485e-01, 1.72121e-01, 2.99894e-02],\n",
      "         [1.14391e+01, 7.92842e+00, 2.40853e+01,  ..., 4.37801e-01, 9.82341e-02, 1.92462e-02],\n",
      "         [1.85547e+01, 6.43557e+00, 3.45100e+01,  ..., 2.78995e-01, 1.41148e-01, 1.51032e-02],\n",
      "         ...,\n",
      "         [1.20455e+03, 7.24890e+02, 6.05792e+01,  ..., 9.43880e-01, 8.70004e-02, 5.62311e-03],\n",
      "         [1.24141e+03, 7.14062e+02, 3.24316e+01,  ..., 9.53914e-01, 7.27447e-02, 8.61464e-03],\n",
      "         [1.27101e+03, 7.22773e+02, 2.66461e+01,  ..., 9.35116e-01, 1.24121e-01, 1.45574e-02]]])\n",
      "[tensor([[5.58210e+02, 4.41130e+02, 6.00908e+02, 4.54510e+02, 6.95936e-01, 3.00000e+00],\n",
      "        [4.01484e+02, 3.88145e+02, 5.70421e+02, 3.99323e+02, 3.16196e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (7/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.729s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.74495e+00, 8.07692e+00, 8.42788e+00,  ..., 2.55409e-01, 1.72084e-01, 3.01653e-02],\n",
      "         [1.14373e+01, 7.93339e+00, 2.40898e+01,  ..., 4.36371e-01, 9.81898e-02, 1.93589e-02],\n",
      "         [1.85535e+01, 6.44151e+00, 3.45162e+01,  ..., 2.78196e-01, 1.40779e-01, 1.52153e-02],\n",
      "         ...,\n",
      "         [1.20494e+03, 7.24933e+02, 6.00734e+01,  ..., 9.42969e-01, 8.78769e-02, 5.63801e-03],\n",
      "         [1.24127e+03, 7.14450e+02, 3.29540e+01,  ..., 9.53257e-01, 7.36955e-02, 8.67203e-03],\n",
      "         [1.27116e+03, 7.23115e+02, 2.66590e+01,  ..., 9.33618e-01, 1.26019e-01, 1.44857e-02]]])\n",
      "[tensor([[5.58210e+02, 4.41133e+02, 6.00910e+02, 4.54511e+02, 6.95794e-01, 3.00000e+00],\n",
      "        [4.01508e+02, 3.88143e+02, 5.70418e+02, 3.99316e+02, 3.15833e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (8/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.875s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.45290e+00, 6.59003e+00, 8.89391e+00,  ..., 6.30222e-01, 1.24125e-01, 1.52625e-02],\n",
      "         [8.71938e+00, 6.09329e+00, 1.75472e+01,  ..., 7.14977e-01, 8.81370e-02, 9.73802e-03],\n",
      "         [1.87580e+01, 4.63939e+00, 2.83049e+01,  ..., 3.85119e-01, 9.21970e-02, 1.12609e-02],\n",
      "         ...,\n",
      "         [1.21805e+03, 7.23614e+02, 5.71934e+01,  ..., 9.22069e-01, 1.29590e-01, 7.00522e-03],\n",
      "         [1.25887e+03, 7.10268e+02, 2.59468e+01,  ..., 9.92941e-01, 8.51082e-03, 7.23675e-03],\n",
      "         [1.26085e+03, 7.10111e+02, 2.54221e+01,  ..., 9.87157e-01, 1.30885e-02, 1.10903e-02]]])\n",
      "[tensor([[5.46666e+02, 4.51011e+02, 5.98878e+02, 4.69009e+02, 7.32657e-01, 3.00000e+00],\n",
      "        [3.95326e+02, 3.92812e+02, 5.67891e+02, 4.04285e+02, 4.58547e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (9/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 patch, Done. (0.824s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.12097e+00, 5.92082e+00, 8.65324e+00,  ..., 1.73452e-01, 2.74014e-01, 3.41698e-02],\n",
      "         [1.05291e+01, 5.90914e+00, 2.18042e+01,  ..., 2.49828e-01, 1.36052e-01, 1.61504e-02],\n",
      "         [1.96532e+01, 5.01097e+00, 3.48300e+01,  ..., 1.06441e-01, 9.44322e-02, 1.68928e-02],\n",
      "         ...,\n",
      "         [1.18179e+03, 7.21969e+02, 4.80769e+01,  ..., 9.33818e-01, 8.14997e-02, 5.28788e-03],\n",
      "         [1.24633e+03, 7.21623e+02, 3.39661e+01,  ..., 9.03781e-01, 1.40609e-01, 7.76578e-03],\n",
      "         [1.27352e+03, 7.20014e+02, 2.29052e+01,  ..., 8.94019e-01, 1.23233e-01, 1.20141e-02]]])\n",
      "[tensor([[539.69537, 464.37625, 592.77032, 482.98874,   0.74857,   3.00000]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (10/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 large_pit, 1 patch, Done. (0.768s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.10716e+00, 4.23529e+00, 8.87120e+00,  ..., 2.44425e-01, 1.83396e-01, 4.36293e-02],\n",
      "         [1.16409e+01, 5.20857e+00, 2.31875e+01,  ..., 3.64263e-01, 1.14007e-01, 2.69605e-02],\n",
      "         [1.95664e+01, 4.85381e+00, 3.42286e+01,  ..., 3.86941e-01, 9.79127e-02, 2.02564e-02],\n",
      "         ...,\n",
      "         [1.20316e+03, 7.18904e+02, 1.87472e+01,  ..., 9.57661e-01, 4.98057e-02, 8.43662e-03],\n",
      "         [1.20561e+03, 7.21490e+02, 2.19533e+01,  ..., 8.90958e-01, 1.63063e-01, 6.88598e-03],\n",
      "         [1.27409e+03, 7.20732e+02, 2.19350e+01,  ..., 8.71025e-01, 1.51498e-01, 8.38809e-03]]])\n",
      "[tensor([[5.29243e+02, 4.74318e+02, 5.87078e+02, 4.95836e+02, 8.14201e-01, 3.00000e+00],\n",
      "        [1.01729e+03, 1.54720e+02, 1.04498e+03, 1.64709e+02, 3.74707e-01, 1.00000e+00],\n",
      "        [3.86921e+02, 5.76802e+02, 4.14151e+02, 6.07408e+02, 3.36985e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (11/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 2 fissures, 1 patch, Done. (0.732s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.23737e+00, 3.93847e+00, 8.13313e+00,  ..., 9.27008e-02, 1.54445e-01, 5.54822e-02],\n",
      "         [1.31896e+01, 4.49107e+00, 2.69239e+01,  ..., 1.77296e-01, 7.01616e-02, 4.64187e-02],\n",
      "         [2.21151e+01, 4.52605e+00, 3.74583e+01,  ..., 3.03721e-01, 6.82223e-02, 3.34606e-02],\n",
      "         ...,\n",
      "         [1.20474e+03, 7.19575e+02, 4.42340e+01,  ..., 9.47180e-01, 6.59518e-02, 7.72726e-03],\n",
      "         [1.22654e+03, 7.17344e+02, 4.19251e+01,  ..., 9.57235e-01, 7.96291e-02, 8.96932e-03],\n",
      "         [1.27278e+03, 7.18981e+02, 1.84805e+01,  ..., 9.15030e-01, 1.16092e-01, 1.58065e-02]]])\n",
      "[tensor([[5.17109e+02, 4.91750e+02, 5.77045e+02, 5.12943e+02, 8.80522e-01, 3.00000e+00],\n",
      "        [3.50515e+02, 6.16482e+02, 3.81230e+02, 6.46468e+02, 5.01685e-01, 0.00000e+00],\n",
      "        [5.81028e+02, 4.11909e+02, 6.51761e+02, 4.18580e+02, 3.17567e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (12/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.789s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.04081e+00, 4.00618e+00, 8.74978e+00,  ..., 2.18262e-01, 1.33095e-01, 5.37922e-02],\n",
      "         [1.35594e+01, 4.66837e+00, 2.71137e+01,  ..., 3.93461e-01, 5.77050e-02, 4.46720e-02],\n",
      "         [2.09353e+01, 5.20316e+00, 3.48105e+01,  ..., 5.05713e-01, 6.78633e-02, 1.77633e-02],\n",
      "         ...,\n",
      "         [1.21074e+03, 7.08337e+02, 1.99624e+01,  ..., 9.74855e-01, 3.07067e-02, 8.76145e-03],\n",
      "         [1.21169e+03, 7.08809e+02, 2.00258e+01,  ..., 9.57123e-01, 4.68191e-02, 8.92862e-03],\n",
      "         [1.27209e+03, 7.29824e+02, 2.76378e+01,  ..., 8.73182e-01, 1.86035e-01, 1.52164e-02]]])\n",
      "[tensor([[5.02265e+02, 5.08300e+02, 5.68056e+02, 5.37183e+02, 7.57717e-01, 3.00000e+00],\n",
      "        [3.01432e+02, 6.64914e+02, 3.39610e+02, 7.06032e+02, 5.70095e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (13/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.836s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.03951e+00, 4.00728e+00, 8.74258e+00,  ..., 2.17132e-01, 1.32935e-01, 5.41100e-02],\n",
      "         [1.35491e+01, 4.66843e+00, 2.70941e+01,  ..., 3.91543e-01, 5.76516e-02, 4.48748e-02],\n",
      "         [2.09304e+01, 5.20461e+00, 3.48042e+01,  ..., 5.03459e-01, 6.78663e-02, 1.78359e-02],\n",
      "         ...,\n",
      "         [1.21073e+03, 7.08338e+02, 1.99917e+01,  ..., 9.75166e-01, 3.05334e-02, 8.64655e-03],\n",
      "         [1.21168e+03, 7.08826e+02, 2.00353e+01,  ..., 9.56967e-01, 4.68277e-02, 8.84471e-03],\n",
      "         [1.27210e+03, 7.29817e+02, 2.76690e+01,  ..., 8.71467e-01, 1.88566e-01, 1.51801e-02]]])\n",
      "[tensor([[5.02284e+02, 5.08279e+02, 5.68040e+02, 5.37183e+02, 7.57522e-01, 3.00000e+00],\n",
      "        [3.01420e+02, 6.64911e+02, 3.39629e+02, 7.06052e+02, 5.72517e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (14/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.878s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.53344e+00, 3.78926e+00, 1.01802e+01,  ..., 3.06034e-01, 1.27314e-01, 6.34450e-02],\n",
      "         [1.26542e+01, 4.66194e+00, 2.39879e+01,  ..., 5.27619e-01, 7.60234e-02, 4.59289e-02],\n",
      "         [2.09730e+01, 4.60892e+00, 3.35087e+01,  ..., 5.47061e-01, 9.67591e-02, 1.19776e-02],\n",
      "         ...,\n",
      "         [1.18081e+03, 7.15827e+02, 5.65332e+01,  ..., 9.63049e-01, 5.85639e-02, 4.06786e-03],\n",
      "         [1.24358e+03, 7.28296e+02, 3.55546e+01,  ..., 8.31733e-01, 1.69066e-01, 1.04751e-02],\n",
      "         [1.27427e+03, 7.34743e+02, 3.07171e+01,  ..., 7.85221e-01, 2.13697e-01, 2.00285e-02]]])\n",
      "[tensor([[4.86204e+02, 5.29810e+02, 5.58460e+02, 5.62739e+02, 8.29217e-01, 3.00000e+00],\n",
      "        [3.23845e+02, 4.16603e+02, 5.49882e+02, 4.33790e+02, 3.64404e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (15/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (0.695s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.67233e+00, 6.32792e+00, 9.06156e+00,  ..., 6.10551e-01, 1.10690e-01, 1.65857e-02],\n",
      "         [1.05748e+01, 6.49767e+00, 2.05508e+01,  ..., 6.79165e-01, 7.67656e-02, 9.81931e-03],\n",
      "         [2.00637e+01, 5.98363e+00, 3.17634e+01,  ..., 4.01277e-01, 1.23852e-01, 1.11304e-02],\n",
      "         ...,\n",
      "         [1.20225e+03, 7.23507e+02, 5.40599e+01,  ..., 9.27433e-01, 8.89400e-02, 4.55051e-03],\n",
      "         [1.24082e+03, 7.25220e+02, 4.92118e+01,  ..., 9.20648e-01, 9.91007e-02, 6.84005e-03],\n",
      "         [1.27145e+03, 7.22336e+02, 3.27500e+01,  ..., 8.71906e-01, 1.54683e-01, 1.14541e-02]]])\n",
      "[tensor([[4.65045e+02, 5.58092e+02, 5.46654e+02, 5.97221e+02, 8.27608e-01, 3.00000e+00],\n",
      "        [3.12704e+02, 4.22762e+02, 5.48809e+02, 4.40259e+02, 4.49601e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (16/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 large_pit, 1 small_pit, 1 patch, Done. (0.977s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.70022e+00, 4.75654e+00, 8.82588e+00,  ..., 5.15474e-01, 1.34610e-01, 1.19557e-02],\n",
      "         [1.21737e+01, 5.36541e+00, 2.45595e+01,  ..., 6.55195e-01, 9.14941e-02, 1.00473e-02],\n",
      "         [1.94378e+01, 5.12621e+00, 3.07642e+01,  ..., 2.72666e-01, 1.79032e-01, 7.66671e-03],\n",
      "         ...,\n",
      "         [1.21015e+03, 7.25000e+02, 3.80784e+01,  ..., 9.04324e-01, 1.63147e-01, 1.21797e-02],\n",
      "         [1.23047e+03, 7.24272e+02, 3.47153e+01,  ..., 8.24795e-01, 2.54768e-01, 1.47261e-02],\n",
      "         [1.27430e+03, 7.18598e+02, 2.38889e+01,  ..., 8.55642e-01, 2.09545e-01, 1.00640e-02]]])\n",
      "[tensor([[4.42350e+02, 5.89426e+02, 5.28328e+02, 6.42516e+02, 8.49983e-01, 3.00000e+00],\n",
      "        [1.06915e+03, 2.68425e+02, 1.08230e+03, 2.76120e+02, 4.81349e-01, 2.00000e+00],\n",
      "        [1.14700e+03, 1.64810e+02, 1.16167e+03, 1.72755e+02, 3.18991e-01, 1.00000e+00],\n",
      "        [3.11886e+02, 4.29697e+02, 5.45823e+02, 4.46964e+02, 3.16775e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (17/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 patch, Done. (1.183s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.33470e+00, 4.05291e+00, 8.87938e+00,  ..., 1.95674e-01, 1.37808e-01, 2.23482e-02],\n",
      "         [1.19007e+01, 4.75669e+00, 2.37320e+01,  ..., 2.70571e-01, 1.08964e-01, 2.13640e-02],\n",
      "         [2.07257e+01, 3.73881e+00, 3.11439e+01,  ..., 4.05747e-01, 1.08624e-01, 1.73506e-02],\n",
      "         ...,\n",
      "         [1.18875e+03, 7.22743e+02, 6.38230e+01,  ..., 9.73391e-01, 5.00987e-02, 4.46155e-03],\n",
      "         [1.23512e+03, 7.21724e+02, 4.72000e+01,  ..., 9.51903e-01, 8.10415e-02, 6.86585e-03],\n",
      "         [1.27111e+03, 7.20703e+02, 3.04671e+01,  ..., 9.10518e-01, 1.24501e-01, 9.75897e-03]]])\n",
      "[tensor([[4.14280e+02, 6.29826e+02, 5.00593e+02, 6.93837e+02, 8.19205e-01, 3.00000e+00],\n",
      "        [3.67746e+02, 4.46252e+02, 5.32868e+02, 4.61484e+02, 3.73560e-01, 0.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (18/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 small_pit, 1 patch, Done. (0.971s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.89246e+00, 5.98841e+00, 5.92441e+00,  ..., 4.02565e-01, 1.36610e-01, 3.55316e-02],\n",
      "         [1.20755e+01, 5.01556e+00, 2.33747e+01,  ..., 6.37099e-01, 7.49184e-02, 3.69097e-02],\n",
      "         [2.18321e+01, 4.16954e+00, 3.50421e+01,  ..., 4.47261e-01, 1.49573e-01, 2.32566e-02],\n",
      "         ...,\n",
      "         [1.19596e+03, 7.27703e+02, 6.05777e+01,  ..., 9.32425e-01, 1.34881e-01, 6.96789e-03],\n",
      "         [1.24011e+03, 7.24830e+02, 4.16666e+01,  ..., 9.22256e-01, 1.54060e-01, 7.77866e-03],\n",
      "         [1.27515e+03, 7.13221e+02, 1.68846e+01,  ..., 9.13273e-01, 1.07937e-01, 9.21149e-03]]])\n",
      "[tensor([[3.75488e+02, 6.82833e+02, 4.80838e+02, 7.30813e+02, 8.23146e-01, 3.00000e+00],\n",
      "        [2.68450e+02, 4.49868e+02, 5.20944e+02, 4.72290e+02, 4.21944e-01, 0.00000e+00],\n",
      "        [1.07958e+03, 2.72984e+02, 1.09228e+03, 2.79689e+02, 3.05408e-01, 2.00000e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (19/590) C:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\for_tracking_tests.mp4: 736x1280 1 fissure, 1 small_pit, 1 patch, Done. (0.912s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.88544e+00, 5.99798e+00, 5.91542e+00,  ..., 4.01248e-01, 1.36496e-01, 3.56597e-02],\n",
      "         [1.20427e+01, 5.01822e+00, 2.33422e+01,  ..., 6.36344e-01, 7.48161e-02, 3.68500e-02],\n",
      "         [2.18345e+01, 4.16857e+00, 3.50469e+01,  ..., 4.46243e-01, 1.49656e-01, 2.33154e-02],\n",
      "         ...,\n",
      "         [1.19603e+03, 7.27697e+02, 6.05792e+01,  ..., 9.32432e-01, 1.34321e-01, 6.99356e-03],\n",
      "         [1.24011e+03, 7.25019e+02, 4.18722e+01,  ..., 9.22326e-01, 1.53741e-01, 7.79757e-03],\n",
      "         [1.27516e+03, 7.13276e+02, 1.68934e+01,  ..., 9.13082e-01, 1.07777e-01, 9.23941e-03]]])\n",
      "[tensor([[3.75416e+02, 6.82812e+02, 4.80829e+02, 7.30840e+02, 8.23431e-01, 3.00000e+00],\n",
      "        [2.68656e+02, 4.49896e+02, 5.21084e+02, 4.72285e+02, 4.21190e-01, 0.00000e+00],\n",
      "        [1.07958e+03, 2.72984e+02, 1.09228e+03, 2.79688e+02, 3.06253e-01, 2.00000e+00]])]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\example.ipynb Ячейка 2\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m new_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfor_tracking_tests\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mp4\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# ВСЕГДА В КОНЦЕ ДОЛЖНО БЫТЬ РАСШИРЕНИЕ МП4\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     all_labels \u001b[39m=\u001b[39m detect(new_file, model_cv)\n",
      "File \u001b[1;32mc:\\Python\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32mc:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\example.ipynb Ячейка 2\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(source, model, imgsz, conf_thres, iou_thres, max_det, device, view_img, save_txt, save_conf, save_crop, nosave, classes, agnostic_nms, augment, visualize, update, line_thickness, hide_labels, hide_conf, half, dnn)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m dt[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m t2 \u001b[39m-\u001b[39m t1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m visualize \u001b[39m=\u001b[39m increment_path(DETECT_IMAGES, \u001b[39mTrue\u001b[39;49;00m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m pred \u001b[39m=\u001b[39m model(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%BD%D0%B0/Desktop/Roads_project/Roads/yolov5/example.ipynb#W1sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m t3 \u001b[39m=\u001b[39m time_sync()\n",
      "File \u001b[1;32mc:\\Users\\Анна\\Desktop\\Roads_project\\Roads\\yolov5\\utils\\general.py:971\u001b[0m, in \u001b[0;36mincrement_path\u001b[1;34m(path, exist_ok, sep, mkdir)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mincrement_path\u001b[39m(path, exist_ok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, mkdir\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    969\u001b[0m     \u001b[39m# Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.\u001b[39;00m\n\u001b[0;32m    970\u001b[0m     path \u001b[39m=\u001b[39m Path(path)  \u001b[39m# os-agnostic\u001b[39;00m\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39;49mexists() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok:\n\u001b[0;32m    972\u001b[0m         path, suffix \u001b[39m=\u001b[39m (path\u001b[39m.\u001b[39mwith_suffix(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m), path\u001b[39m.\u001b[39msuffix) \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mis_file() \u001b[39melse\u001b[39;00m (path, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    974\u001b[0m         \u001b[39m# Method 1\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\lib\\pathlib.py:1400\u001b[0m, in \u001b[0;36mPath.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m \u001b[39mWhether this path exists.\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1400\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstat()\n\u001b[0;32m   1401\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1402\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[1;32mc:\\Python\\lib\\pathlib.py:1197\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1193\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[39m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[39m    os.stat() does.\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mstat(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "# Load model\n",
    "device = 'cpu'\n",
    "# загрузка модели\n",
    "device = select_device(device)\n",
    "model_cv = DetectMultiBackend('C:/Users/Анна/Desktop/Roads_project/Roads/yolov5/runs/train/exp/weights/yolo_by_roads_v4.pt', device=device, dnn=False, fp16=False)\n",
    "\n",
    "# видео\n",
    "new_file = 'for_tracking_tests' + '.mp4' # ВСЕГДА В КОНЦЕ ДОЛЖНО БЫТЬ РАСШИРЕНИЕ МП4\n",
    "with torch.no_grad():\n",
    "    all_labels = detect(new_file, model_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eee4b7b-71fc-4a00-a293-17c61cdef357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DarkSidius\\\\Downloads\\\\Telegram Desktop\\\\yolov5-master\\\\yolov5-master'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8905f54-7b37-4d26-8567-388368f52a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
